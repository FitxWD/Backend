{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13010713,"sourceType":"datasetVersion","datasetId":8237142}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:38.106141Z","iopub.execute_input":"2025-10-24T05:16:38.106706Z","iopub.status.idle":"2025-10-24T05:16:38.530899Z","shell.execute_reply.started":"2025-10-24T05:16:38.106657Z","shell.execute_reply":"2025-10-24T05:16:38.529831Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/clustered-data/clustered_data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:38.532785Z","iopub.execute_input":"2025-10-24T05:16:38.533201Z","iopub.status.idle":"2025-10-24T05:16:40.310279Z","shell.execute_reply.started":"2025-10-24T05:16:38.533174Z","shell.execute_reply":"2025-10-24T05:16:40.309415Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.311455Z","iopub.execute_input":"2025-10-24T05:16:40.311757Z","iopub.status.idle":"2025-10-24T05:16:40.316767Z","shell.execute_reply.started":"2025-10-24T05:16:40.311727Z","shell.execute_reply":"2025-10-24T05:16:40.315732Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.317668Z","iopub.execute_input":"2025-10-24T05:16:40.317965Z","iopub.status.idle":"2025-10-24T05:16:40.367896Z","shell.execute_reply.started":"2025-10-24T05:16:40.317942Z","shell.execute_reply":"2025-10-24T05:16:40.366813Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        age  height_cm  weight_kg    bmi    activity_type  duration_minutes  \\\n0        56      165.3      50.55  18.50          Dancing              42.1   \n1        56      165.3      55.38  20.27         Swimming              66.9   \n2        56      165.3      56.49  20.68         Swimming              20.0   \n3        56      165.3      52.23  19.12  Weight Training              23.5   \n4        56      165.3      53.96  19.75         Swimming              75.0   \n...     ...        ...        ...    ...              ...               ...   \n687696   38      165.7      57.06  20.78       Basketball             109.6   \n687697   38      165.7      55.24  20.12       Basketball             145.3   \n687698   38      165.7      60.26  21.95             Yoga              84.9   \n687699   38      165.7      59.30  21.60       Basketball             107.1   \n687700   38      165.7      57.56  20.96             Yoga              88.3   \n\n        intensity  calories_burned  daily_steps  avg_heart_rate  \\\n0               0              3.3         7128             103   \n1               0              2.9         7925             102   \n2               1              2.6         7557             126   \n3               1             10.7        11120             141   \n4               1             12.7         5406             112   \n...           ...              ...          ...             ...   \n687696          1             13.2         6911             139   \n687697          0              6.3         8932             113   \n687698          0              9.1         8864             120   \n687699          1             32.6         7455             135   \n687700          2              3.8         9737             164   \n\n        resting_heart_rate  blood_pressure_systolic  blood_pressure_diastolic  \\\n0                     69.5                    110.7                      72.9   \n1                     69.5                    110.7                      72.9   \n2                     69.5                    110.7                      72.9   \n3                     69.5                    110.7                      72.9   \n4                     69.5                    110.7                      72.9   \n...                    ...                      ...                       ...   \n687696                66.5                    127.0                      75.5   \n687697                66.5                    127.0                      75.5   \n687698                66.5                    127.0                      75.5   \n687699                66.5                    127.0                      75.5   \n687700                66.5                    127.0                      75.5   \n\n        endurance_level  sleep_hours  stress_level  hydration_level  \\\n0                  5.37          6.6             4              1.5   \n1                  5.39          8.1             3              1.8   \n2                  5.42          6.2             5              2.7   \n3                  5.44          7.2             4              2.6   \n4                  5.47          7.1             7              1.5   \n...                 ...          ...           ...              ...   \n687696            11.29          7.4             4              1.9   \n687697            11.31          8.5             5              2.6   \n687698            11.34          8.2             4              1.8   \n687699            11.36          8.5             6              2.1   \n687700            11.39          7.4             3              2.0   \n\n        fitness_level  gender_F  gender_M  smoking_status_Current  \\\n0                0.04       1.0       0.0                     0.0   \n1                0.07       1.0       0.0                     0.0   \n2                0.09       1.0       0.0                     0.0   \n3                0.21       1.0       0.0                     0.0   \n4                0.33       1.0       0.0                     0.0   \n...               ...       ...       ...                     ...   \n687696          17.13       1.0       0.0                     0.0   \n687697          17.16       1.0       0.0                     0.0   \n687698          17.26       1.0       0.0                     0.0   \n687699          17.39       1.0       0.0                     0.0   \n687700          17.43       1.0       0.0                     0.0   \n\n        smoking_status_Former  health_condition_Asthma  \\\n0                         0.0                      0.0   \n1                         0.0                      0.0   \n2                         0.0                      0.0   \n3                         0.0                      0.0   \n4                         0.0                      0.0   \n...                       ...                      ...   \n687696                    0.0                      0.0   \n687697                    0.0                      0.0   \n687698                    0.0                      0.0   \n687699                    0.0                      0.0   \n687700                    0.0                      0.0   \n\n        health_condition_Diabetes  health_condition_Hypertension  cluster  \\\n0                             0.0                            0.0        0   \n1                             0.0                            0.0        0   \n2                             0.0                            0.0        0   \n3                             0.0                            0.0        0   \n4                             0.0                            0.0        0   \n...                           ...                            ...      ...   \n687696                        0.0                            0.0        2   \n687697                        0.0                            0.0        2   \n687698                        0.0                            0.0        2   \n687699                        0.0                            0.0        2   \n687700                        0.0                            0.0        4   \n\n        activity_cluster  \n0                      4  \n1                      0  \n2                      0  \n3                      4  \n4                      0  \n...                  ...  \n687696                 0  \n687697                 0  \n687698                 1  \n687699                 0  \n687700                 1  \n\n[687701 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>height_cm</th>\n      <th>weight_kg</th>\n      <th>bmi</th>\n      <th>activity_type</th>\n      <th>duration_minutes</th>\n      <th>intensity</th>\n      <th>calories_burned</th>\n      <th>daily_steps</th>\n      <th>avg_heart_rate</th>\n      <th>resting_heart_rate</th>\n      <th>blood_pressure_systolic</th>\n      <th>blood_pressure_diastolic</th>\n      <th>endurance_level</th>\n      <th>sleep_hours</th>\n      <th>stress_level</th>\n      <th>hydration_level</th>\n      <th>fitness_level</th>\n      <th>gender_F</th>\n      <th>gender_M</th>\n      <th>smoking_status_Current</th>\n      <th>smoking_status_Former</th>\n      <th>health_condition_Asthma</th>\n      <th>health_condition_Diabetes</th>\n      <th>health_condition_Hypertension</th>\n      <th>cluster</th>\n      <th>activity_cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>165.3</td>\n      <td>50.55</td>\n      <td>18.50</td>\n      <td>Dancing</td>\n      <td>42.1</td>\n      <td>0</td>\n      <td>3.3</td>\n      <td>7128</td>\n      <td>103</td>\n      <td>69.5</td>\n      <td>110.7</td>\n      <td>72.9</td>\n      <td>5.37</td>\n      <td>6.6</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.04</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>165.3</td>\n      <td>55.38</td>\n      <td>20.27</td>\n      <td>Swimming</td>\n      <td>66.9</td>\n      <td>0</td>\n      <td>2.9</td>\n      <td>7925</td>\n      <td>102</td>\n      <td>69.5</td>\n      <td>110.7</td>\n      <td>72.9</td>\n      <td>5.39</td>\n      <td>8.1</td>\n      <td>3</td>\n      <td>1.8</td>\n      <td>0.07</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56</td>\n      <td>165.3</td>\n      <td>56.49</td>\n      <td>20.68</td>\n      <td>Swimming</td>\n      <td>20.0</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>7557</td>\n      <td>126</td>\n      <td>69.5</td>\n      <td>110.7</td>\n      <td>72.9</td>\n      <td>5.42</td>\n      <td>6.2</td>\n      <td>5</td>\n      <td>2.7</td>\n      <td>0.09</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>165.3</td>\n      <td>52.23</td>\n      <td>19.12</td>\n      <td>Weight Training</td>\n      <td>23.5</td>\n      <td>1</td>\n      <td>10.7</td>\n      <td>11120</td>\n      <td>141</td>\n      <td>69.5</td>\n      <td>110.7</td>\n      <td>72.9</td>\n      <td>5.44</td>\n      <td>7.2</td>\n      <td>4</td>\n      <td>2.6</td>\n      <td>0.21</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>165.3</td>\n      <td>53.96</td>\n      <td>19.75</td>\n      <td>Swimming</td>\n      <td>75.0</td>\n      <td>1</td>\n      <td>12.7</td>\n      <td>5406</td>\n      <td>112</td>\n      <td>69.5</td>\n      <td>110.7</td>\n      <td>72.9</td>\n      <td>5.47</td>\n      <td>7.1</td>\n      <td>7</td>\n      <td>1.5</td>\n      <td>0.33</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>687696</th>\n      <td>38</td>\n      <td>165.7</td>\n      <td>57.06</td>\n      <td>20.78</td>\n      <td>Basketball</td>\n      <td>109.6</td>\n      <td>1</td>\n      <td>13.2</td>\n      <td>6911</td>\n      <td>139</td>\n      <td>66.5</td>\n      <td>127.0</td>\n      <td>75.5</td>\n      <td>11.29</td>\n      <td>7.4</td>\n      <td>4</td>\n      <td>1.9</td>\n      <td>17.13</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687697</th>\n      <td>38</td>\n      <td>165.7</td>\n      <td>55.24</td>\n      <td>20.12</td>\n      <td>Basketball</td>\n      <td>145.3</td>\n      <td>0</td>\n      <td>6.3</td>\n      <td>8932</td>\n      <td>113</td>\n      <td>66.5</td>\n      <td>127.0</td>\n      <td>75.5</td>\n      <td>11.31</td>\n      <td>8.5</td>\n      <td>5</td>\n      <td>2.6</td>\n      <td>17.16</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687698</th>\n      <td>38</td>\n      <td>165.7</td>\n      <td>60.26</td>\n      <td>21.95</td>\n      <td>Yoga</td>\n      <td>84.9</td>\n      <td>0</td>\n      <td>9.1</td>\n      <td>8864</td>\n      <td>120</td>\n      <td>66.5</td>\n      <td>127.0</td>\n      <td>75.5</td>\n      <td>11.34</td>\n      <td>8.2</td>\n      <td>4</td>\n      <td>1.8</td>\n      <td>17.26</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>687699</th>\n      <td>38</td>\n      <td>165.7</td>\n      <td>59.30</td>\n      <td>21.60</td>\n      <td>Basketball</td>\n      <td>107.1</td>\n      <td>1</td>\n      <td>32.6</td>\n      <td>7455</td>\n      <td>135</td>\n      <td>66.5</td>\n      <td>127.0</td>\n      <td>75.5</td>\n      <td>11.36</td>\n      <td>8.5</td>\n      <td>6</td>\n      <td>2.1</td>\n      <td>17.39</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687700</th>\n      <td>38</td>\n      <td>165.7</td>\n      <td>57.56</td>\n      <td>20.96</td>\n      <td>Yoga</td>\n      <td>88.3</td>\n      <td>2</td>\n      <td>3.8</td>\n      <td>9737</td>\n      <td>164</td>\n      <td>66.5</td>\n      <td>127.0</td>\n      <td>75.5</td>\n      <td>11.39</td>\n      <td>7.4</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>17.43</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>687701 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.370624Z","iopub.execute_input":"2025-10-24T05:16:40.370991Z","iopub.status.idle":"2025-10-24T05:16:40.461214Z","shell.execute_reply.started":"2025-10-24T05:16:40.370966Z","shell.execute_reply":"2025-10-24T05:16:40.460214Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 687701 entries, 0 to 687700\nData columns (total 27 columns):\n #   Column                         Non-Null Count   Dtype  \n---  ------                         --------------   -----  \n 0   age                            687701 non-null  int64  \n 1   height_cm                      687701 non-null  float64\n 2   weight_kg                      687701 non-null  float64\n 3   bmi                            687701 non-null  float64\n 4   activity_type                  687701 non-null  object \n 5   duration_minutes               687701 non-null  float64\n 6   intensity                      687701 non-null  int64  \n 7   calories_burned                687701 non-null  float64\n 8   daily_steps                    687701 non-null  int64  \n 9   avg_heart_rate                 687701 non-null  int64  \n 10  resting_heart_rate             687701 non-null  float64\n 11  blood_pressure_systolic        687701 non-null  float64\n 12  blood_pressure_diastolic       687701 non-null  float64\n 13  endurance_level                687701 non-null  float64\n 14  sleep_hours                    687701 non-null  float64\n 15  stress_level                   687701 non-null  int64  \n 16  hydration_level                687701 non-null  float64\n 17  fitness_level                  687701 non-null  float64\n 18  gender_F                       687701 non-null  float64\n 19  gender_M                       687701 non-null  float64\n 20  smoking_status_Current         687701 non-null  float64\n 21  smoking_status_Former          687701 non-null  float64\n 22  health_condition_Asthma        687701 non-null  float64\n 23  health_condition_Diabetes      687701 non-null  float64\n 24  health_condition_Hypertension  687701 non-null  float64\n 25  cluster                        687701 non-null  int64  \n 26  activity_cluster               687701 non-null  int64  \ndtypes: float64(19), int64(7), object(1)\nmemory usage: 141.7+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class_counts = df[\"activity_cluster\"].value_counts()\nprint(class_counts)\n\nclass_percentages = df[\"activity_cluster\"].value_counts(normalize=True) * 100\nprint(class_percentages)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.462096Z","iopub.execute_input":"2025-10-24T05:16:40.462401Z","iopub.status.idle":"2025-10-24T05:16:40.480803Z","shell.execute_reply.started":"2025-10-24T05:16:40.462373Z","shell.execute_reply":"2025-10-24T05:16:40.479889Z"}},"outputs":[{"name":"stdout","text":"activity_cluster\n0    205101\n4    138854\n1    138038\n3    136332\n2     69376\nName: count, dtype: int64\nactivity_cluster\n0    29.824153\n4    20.191042\n1    20.072386\n3    19.824313\n2    10.088105\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"X = df.drop(columns=[\"activity_cluster\", \"cluster\", \"activity_type\", \"avg_heart_rate\"])\ny = df[\"activity_cluster\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.481808Z","iopub.execute_input":"2025-10-24T05:16:40.482202Z","iopub.status.idle":"2025-10-24T05:16:40.538964Z","shell.execute_reply.started":"2025-10-24T05:16:40.482166Z","shell.execute_reply":"2025-10-24T05:16:40.537900Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns\n\n# ---------------------------\n# Create preprocessing pipeline\n# ---------------------------\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n    ]\n)\n\n# ---------------------------\n# Build full pipeline with SVM\n# ---------------------------\nsvm_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', SVC(kernel='rbf', random_state=42))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:40.539881Z","iopub.execute_input":"2025-10-24T05:16:40.540137Z","iopub.status.idle":"2025-10-24T05:16:41.243864Z","shell.execute_reply.started":"2025-10-24T05:16:40.540116Z","shell.execute_reply":"2025-10-24T05:16:41.242784Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import VotingClassifier\n\n# -------------------------------\n# Split data 80/20 (train/test)\n# -------------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# -------------------------------\n# Tuned models\n# -------------------------------\n\nxgb_model = XGBClassifier(\n    n_estimators=271,\n    max_depth=11,\n    learning_rate=0.2047796426757615,\n    subsample=0.8851985734223917,\n    colsample_bytree=0.7033309928502494,\n    gamma=0.44512356222236044,\n    random_state=42,\n    eval_metric='logloss',\n    use_label_encoder=False\n)\n\nlgbm_model = LGBMClassifier(\n    n_estimators=378,\n    max_depth=11,\n    learning_rate=0.22408224744749508,\n    num_leaves=165,\n    subsample=0.6086742677723623,\n    colsample_bytree=0.733633308095874,\n    random_state=42,\n    verbose=-1\n)\n\n# -------------------------------\n# Ensemble with soft voting\n# -------------------------------\nensemble = VotingClassifier(\n    estimators=[('xgb', xgb_model), ('lgbm', lgbm_model)],\n    voting='soft'\n)\n\n# -------------------------------\n# Train ensemble\n# -------------------------------\nensemble.fit(X_train, y_train)\n\n# -------------------------------\n# Test predictions\n# -------------------------------\ny_pred = ensemble.predict(X_test)\n\n# -------------------------------\n# Evaluation\n# -------------------------------\nacc = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f\"Ensemble Accuracy: {acc:.4f}\")\nprint(f\"Ensemble F1 Score: {f1:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:16:41.244891Z","iopub.execute_input":"2025-10-24T05:16:41.245378Z","iopub.status.idle":"2025-10-24T05:19:54.226941Z","shell.execute_reply.started":"2025-10-24T05:16:41.245327Z","shell.execute_reply":"2025-10-24T05:19:54.225856Z"}},"outputs":[{"name":"stdout","text":"Ensemble Accuracy: 0.5509\nEnsemble F1 Score: 0.5405\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.52      0.65      0.58     41020\n           1       0.54      0.77      0.64     27608\n           2       0.81      0.36      0.50     13875\n           3       0.61      0.38      0.47     27267\n           4       0.53      0.44      0.48     27771\n\n    accuracy                           0.55    137541\n   macro avg       0.60      0.52      0.53    137541\nweighted avg       0.57      0.55      0.54    137541\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:19:54.227886Z","iopub.execute_input":"2025-10-24T05:19:54.228376Z","iopub.status.idle":"2025-10-24T05:19:54.235464Z","shell.execute_reply.started":"2025-10-24T05:19:54.228326Z","shell.execute_reply":"2025-10-24T05:19:54.234410Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Index(['age', 'height_cm', 'weight_kg', 'bmi', 'duration_minutes', 'intensity',\n       'calories_burned', 'daily_steps', 'resting_heart_rate',\n       'blood_pressure_systolic', 'blood_pressure_diastolic',\n       'endurance_level', 'sleep_hours', 'stress_level', 'hydration_level',\n       'fitness_level', 'gender_F', 'gender_M', 'smoking_status_Current',\n       'smoking_status_Former', 'health_condition_Asthma',\n       'health_condition_Diabetes', 'health_condition_Hypertension'],\n      dtype='object')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import joblib\n\njoblib.dump(ensemble, 'ensemble_model.joblib')\n\nensemble_loaded = joblib.load('ensemble_model.joblib')\ny_pred_loaded = ensemble_loaded.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:19:54.236845Z","iopub.execute_input":"2025-10-24T05:19:54.237182Z","iopub.status.idle":"2025-10-24T05:20:21.135060Z","shell.execute_reply.started":"2025-10-24T05:19:54.237151Z","shell.execute_reply":"2025-10-24T05:20:21.133932Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"y_pred_loaded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:20:21.135979Z","iopub.execute_input":"2025-10-24T05:20:21.136240Z","iopub.status.idle":"2025-10-24T05:20:21.142838Z","shell.execute_reply.started":"2025-10-24T05:20:21.136218Z","shell.execute_reply":"2025-10-24T05:20:21.141792Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([3, 4, 0, ..., 0, 0, 4])"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\n\n# Function to map fitness level\ndef map_fitness_level(fitness_level):\n    fitness_level = fitness_level.lower()\n    fitness_bins = {\n        \"beginner\": 3.5185345025263106,\n        \"intermediate\": 10.509214058636523,\n        \"advanced\": 16.57287187522573\n    }\n    if \"beginner\" in fitness_level:\n        return fitness_bins[\"beginner\"]\n    elif \"intermediate\" in fitness_level:\n        return fitness_bins[\"intermediate\"]\n    elif \"advanced\" in fitness_level:\n        return fitness_bins[\"advanced\"]\n    else:\n        return fitness_bins[\"beginner\"]\n\n# Function to map endurance level\ndef map_endurance_level(endurance):\n    endurance = endurance.lower()\n    endurance_bins = {\n        \"low\": 7.08634417419755,\n        \"average\": 9.74383342115639,\n        \"high\": 12.386626194708358\n    }\n    if \"low\" in endurance:\n        return endurance_bins[\"low\"]\n    elif \"average\" in endurance or \"medium\" in endurance:\n        return endurance_bins[\"average\"]\n    elif \"high\" in endurance:\n        return endurance_bins[\"high\"]\n    else:\n        return endurance_bins[\"average\"]\n\n# Function to calculate calories burned\ndef calculate_calories(features):\n    if features['duration_minutes'] > 0:\n        mets = {0: 0.3, 1: 0.5, 2: 0.8}.get(features['intensity'], 5)\n        hours = features['duration_minutes'] / 60\n        estimated_calories = mets * features['weight_kg'] * hours\n        return int(estimated_calories)\n    else:\n        return 0\n\n# Input features (replace with actual data)\nfeatures = {\n    'age': 25,\n    'height_cm': 170,\n    'weight_kg': 65,\n    'bmi': 22.5,\n    'duration_minutes': 45,\n    'intensity': 2, \n    'daily_steps': 8000,\n    'resting_heart_rate': 70,\n    'blood_pressure_systolic': 120,\n    'blood_pressure_diastolic': 80,\n    'sleep_hours': 7,\n    'stress_level': 3,\n    'hydration_level': 8,\n    'gender_F': 1,\n    'gender_M': 0,\n    'smoking_status_Current': 0,\n    'smoking_status_Former': 0,\n    'health_condition_Asthma': 0,\n    'health_condition_Diabetes': 0,\n    'health_condition_Hypertension': 0,\n    'fitness_level': 'Intermediate',  \n    'endurance_level': 'High'         \n}\n\n# Convert text levels to numeric and calculate calories\nfeatures['fitness_level'] = map_fitness_level(features['fitness_level'])\nfeatures['endurance_level'] = map_endurance_level(features['endurance_level'])\nfeatures['calories_burned'] = calculate_calories(features)\n\n# Arrange in correct order for the model\ncolumns = [\n    'age', 'height_cm', 'weight_kg', 'bmi', 'duration_minutes', 'intensity',\n    'calories_burned', 'daily_steps', 'resting_heart_rate',\n    'blood_pressure_systolic', 'blood_pressure_diastolic',\n    'endurance_level', 'sleep_hours', 'stress_level', 'hydration_level',\n    'fitness_level', 'gender_F', 'gender_M', 'smoking_status_Current',\n    'smoking_status_Former', 'health_condition_Asthma',\n    'health_condition_Diabetes', 'health_condition_Hypertension'\n]\n\n# Create DataFrame in correct order\ninput_data = pd.DataFrame([[features[col] for col in columns]], columns=columns)\n\n# Get prediction from model\nprediction = ensemble_loaded.predict(input_data)\nprint(\"Prediction:\", prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:20:21.144164Z","iopub.execute_input":"2025-10-24T05:20:21.144550Z","iopub.status.idle":"2025-10-24T05:20:21.175758Z","shell.execute_reply.started":"2025-10-24T05:20:21.144520Z","shell.execute_reply":"2025-10-24T05:20:21.174744Z"}},"outputs":[{"name":"stdout","text":"Prediction: [0]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df[\"fitness_level_original\"] = df[\"fitness_level\"] \ndf[\"endurance_level_original\"] = df[\"endurance_level\"]\n\n# Define bins\nfitness_bins = [-float(\"inf\"), 7, 14, float(\"inf\")]\nfitness_labels = [\"Low\", \"Medium\", \"High\"]\n\nendurance_bins = [-float(\"inf\"), 8.5, 11, float(\"inf\")]\nendurance_labels = [\"Low\", \"Medium\", \"High\"]\n\n# Bin data\ndf[\"fitness_bin\"] = pd.cut(df[\"fitness_level_original\"], bins=fitness_bins, labels=fitness_labels)\ndf[\"endurance_bin\"] = pd.cut(df[\"endurance_level_original\"], bins=endurance_bins, labels=endurance_labels)\n\n# Compute mean values per bin\nfitness_means = df.groupby(\"fitness_bin\")[\"fitness_level_original\"].mean().to_dict()\nendurance_means = df.groupby(\"endurance_bin\")[\"endurance_level_original\"].mean().to_dict()\n\nprint(\"Representative values for Fitness bins:\", fitness_means)\nprint(\"Representative values for Endurance bins:\", endurance_means)\n\n# ------------------------------\n# Function for prediction mapping\n# ------------------------------\ndef map_user_input_to_value(fitness_bin, endurance_bin):\n    \"\"\"Convert user-friendly Low/Medium/High input to numeric values based on dataset means\"\"\"\n    fitness_val = fitness_means.get(fitness_bin, None)\n    endurance_val = endurance_means.get(endurance_bin, None)\n    return fitness_val, endurance_val\n\n# ------------------------------\n# Example usage\n# ------------------------------\nuser_fitness = \"Medium\"   # user selects\nuser_endurance = \"Low\"\n\nfitness_val, endurance_val = map_user_input_to_value(user_fitness, user_endurance)\n\nprint(f\"Mapped values → Fitness: {fitness_val}, Endurance: {endurance_val}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:20:21.179107Z","iopub.execute_input":"2025-10-24T05:20:21.179445Z","iopub.status.idle":"2025-10-24T05:20:21.252117Z","shell.execute_reply.started":"2025-10-24T05:20:21.179422Z","shell.execute_reply":"2025-10-24T05:20:21.250913Z"}},"outputs":[{"name":"stdout","text":"Representative values for Fitness bins: {'Low': 3.5185345025263106, 'Medium': 10.509214058636523, 'High': 16.57287187522573}\nRepresentative values for Endurance bins: {'Low': 7.08634417419755, 'Medium': 9.74383342115639, 'High': 12.386626194708358}\nMapped values → Fitness: 10.509214058636523, Endurance: 7.08634417419755\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_205/2977126458.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  fitness_means = df.groupby(\"fitness_bin\")[\"fitness_level_original\"].mean().to_dict()\n/tmp/ipykernel_205/2977126458.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  endurance_means = df.groupby(\"endurance_bin\")[\"endurance_level_original\"].mean().to_dict()\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import TensorDataset, DataLoader\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.metrics import accuracy_score\n# import numpy as np\n\n# # -----------------------------\n# # 1. Prepare Data\n# # -----------------------------\n# X = df.drop(columns=[\"activity_cluster\", \"cluster\", \"activity_type\"])\n# y = df[\"activity_cluster\"]\n\n# # Scale features\n# scaler = StandardScaler()\n# X_scaled = scaler.fit_transform(X)\n\n# # Train-test split\n# X_train, X_val, y_train, y_val = train_test_split(\n#     X_scaled, y, test_size=0.2, random_state=42, stratify=y\n# )\n\n# # Convert to torch tensors\n# X_train = torch.tensor(X_train, dtype=torch.float32)\n# X_val = torch.tensor(X_val, dtype=torch.float32)\n# y_train = torch.tensor(y_train.values, dtype=torch.long)\n# y_val = torch.tensor(y_val.values, dtype=torch.long)\n\n# # Create DataLoaders\n# batch_size = 2048\n# train_dataset = TensorDataset(X_train, y_train)\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# val_dataset = TensorDataset(X_val, y_val)\n# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n# # -----------------------------\n# # 2. Improved Deep Network\n# # -----------------------------\n# class ImprovedNet(nn.Module):\n#     def __init__(self, input_dim, num_classes):\n#         super().__init__()\n#         self.net = nn.Sequential(\n#             nn.Linear(input_dim, 512),\n#             nn.BatchNorm1d(512),\n#             nn.GELU(),\n#             nn.Dropout(0.4),\n            \n#             nn.Linear(512, 256),\n#             nn.BatchNorm1d(256),\n#             nn.GELU(),\n#             nn.Dropout(0.3),\n            \n#             nn.Linear(256, 128),\n#             nn.BatchNorm1d(128),\n#             nn.GELU(),\n#             nn.Dropout(0.2),\n            \n#             nn.Linear(128, num_classes)\n#         )\n\n#     def forward(self, x):\n#         return self.net(x)\n\n# input_dim = X_train.shape[1]\n# num_classes = len(np.unique(y))\n# model = ImprovedNet(input_dim, num_classes)\n\n# # -----------------------------\n# # 3. Training Setup\n# # -----------------------------\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n\n# # Scheduler: reduce LR by factor of 0.5 if val loss hasn’t improved for 3 epochs\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#     optimizer, mode='min', factor=0.5, patience=3, verbose=True\n# )\n\n# epochs = 50\n# patience = 7  # early stopping patience\n# best_val_loss = float('inf')\n# counter = 0\n\n# # -----------------------------\n# # 4. Training Loop with Early Stopping + Scheduler\n# # -----------------------------\n# for epoch in range(epochs):\n#     model.train()\n#     for batch_x, batch_y in train_loader:\n#         optimizer.zero_grad()\n#         outputs = model(batch_x)\n#         loss = criterion(outputs, batch_y)\n#         loss.backward()\n#         optimizer.step()\n\n#     # Validation\n#     model.eval()\n#     val_losses = []\n#     val_preds = []\n#     val_targets = []\n#     with torch.no_grad():\n#         for batch_x, batch_y in val_loader:\n#             outputs = model(batch_x)\n#             val_loss = criterion(outputs, batch_y)\n#             val_losses.append(val_loss.item())\n#             preds = outputs.argmax(dim=1)\n#             val_preds.append(preds)\n#             val_targets.append(batch_y)\n\n#     avg_val_loss = np.mean(val_losses)\n#     val_preds = torch.cat(val_preds)\n#     val_targets = torch.cat(val_targets)\n#     val_acc = accuracy_score(val_targets.cpu(), val_preds.cpu())\n\n#     # Step scheduler\n#     scheduler.step(avg_val_loss)\n\n#     print(f\"Epoch {epoch+1}/{epochs}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_acc:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n\n#     # Early Stopping\n#     if avg_val_loss < best_val_loss:\n#         best_val_loss = avg_val_loss\n#         counter = 0\n#         torch.save(model.state_dict(), \"best_model.pth\")  # save best model\n#     else:\n#         counter += 1\n#         if counter >= patience:\n#             print(\"Early stopping triggered!\")\n#             break\n\n# print(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:20:21.253231Z","iopub.execute_input":"2025-10-24T05:20:21.253587Z","iopub.status.idle":"2025-10-24T05:20:21.261058Z","shell.execute_reply.started":"2025-10-24T05:20:21.253557Z","shell.execute_reply":"2025-10-24T05:20:21.259986Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# import tensorflow as tf\n# from sklearn.svm import SVC\n# from sklearn.pipeline import Pipeline\n# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n# from sklearn.compose import ColumnTransformer\n# from sklearn.base import BaseEstimator, TransformerMixin\n# import numpy as np\n\n# # ---------------------------\n# # Custom transformer: Deep feature extractor\n# # ---------------------------\n# class DeepFeatureExtractor(BaseEstimator, TransformerMixin):\n#     def __init__(self, input_dim, embedding_dim=32, epochs=10, batch_size=32):\n#         self.input_dim = input_dim\n#         self.embedding_dim = embedding_dim\n#         self.epochs = epochs\n#         self.batch_size = batch_size\n#         self.model = None\n    \n#     def fit(self, X, y=None):\n#         # Simple autoencoder-like NN to learn embeddings\n#         inputs = tf.keras.Input(shape=(self.input_dim,))\n#         x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n#         x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n#         embeddings = tf.keras.layers.Dense(self.embedding_dim, activation=\"relu\")(x)\n#         outputs = tf.keras.layers.Dense(self.input_dim, activation=\"linear\")(embeddings)\n\n#         autoencoder = tf.keras.Model(inputs, outputs)\n#         autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n#         autoencoder.fit(X, X, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n\n#         # Store encoder part only\n#         self.model = tf.keras.Model(inputs, embeddings)\n#         return self\n    \n#     def transform(self, X):\n#         return self.model.predict(X, verbose=0)\n\n# # ---------------------------\n# # Preprocessing pipeline\n# # ---------------------------\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', StandardScaler(), numeric_cols),\n#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n#     ]\n# )\n\n# # ---------------------------\n# # Hybrid pipeline: Preprocess → Deep NN features → SVM\n# # ---------------------------\n# hybrid_pipeline = Pipeline(steps=[\n#     ('preprocessor', preprocessor),\n#     ('deep_features', DeepFeatureExtractor(input_dim=len(numeric_cols) + len(categorical_cols))),\n#     ('classifier', SVC(kernel='rbf', random_state=42))\n# ])\n\n# # ---------------------------\n# # Train/test split\n# # ---------------------------\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Fit hybrid model\n# hybrid_pipeline.fit(X_train, y_train)\n\n# # Evaluate\n# y_pred = hybrid_pipeline.predict(X_test)\n# print(\"Hybrid Model Accuracy:\", accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T05:20:21.261933Z","iopub.execute_input":"2025-10-24T05:20:21.262227Z","iopub.status.idle":"2025-10-24T05:20:21.285375Z","shell.execute_reply.started":"2025-10-24T05:20:21.262204Z","shell.execute_reply":"2025-10-24T05:20:21.284214Z"}},"outputs":[],"execution_count":16}]}