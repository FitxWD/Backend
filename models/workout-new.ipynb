{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:00.285751Z",
     "iopub.status.busy": "2025-10-06T12:35:00.285452Z",
     "iopub.status.idle": "2025-10-06T12:35:02.302492Z",
     "shell.execute_reply": "2025-10-06T12:35:02.301539Z",
     "shell.execute_reply.started": "2025-10-06T12:35:00.285707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:02.304966Z",
     "iopub.status.busy": "2025-10-06T12:35:02.304419Z",
     "iopub.status.idle": "2025-10-06T12:35:04.055172Z",
     "shell.execute_reply": "2025-10-06T12:35:04.054119Z",
     "shell.execute_reply.started": "2025-10-06T12:35:02.304941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"clustered_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:04.056131Z",
     "iopub.status.busy": "2025-10-06T12:35:04.055934Z",
     "iopub.status.idle": "2025-10-06T12:35:04.185627Z",
     "shell.execute_reply": "2025-10-06T12:35:04.184800Z",
     "shell.execute_reply.started": "2025-10-06T12:35:04.056115Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>bmi</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>intensity</th>\n",
       "      <th>calories_burned</th>\n",
       "      <th>daily_steps</th>\n",
       "      <th>avg_heart_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>fitness_level</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>smoking_status_Current</th>\n",
       "      <th>smoking_status_Former</th>\n",
       "      <th>health_condition_Asthma</th>\n",
       "      <th>health_condition_Diabetes</th>\n",
       "      <th>health_condition_Hypertension</th>\n",
       "      <th>cluster</th>\n",
       "      <th>activity_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>165.3</td>\n",
       "      <td>50.55</td>\n",
       "      <td>18.50</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7128</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>165.3</td>\n",
       "      <td>55.38</td>\n",
       "      <td>20.27</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7925</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>165.3</td>\n",
       "      <td>56.49</td>\n",
       "      <td>20.68</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7557</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>165.3</td>\n",
       "      <td>52.23</td>\n",
       "      <td>19.12</td>\n",
       "      <td>Weight Training</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>11120</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>165.3</td>\n",
       "      <td>53.96</td>\n",
       "      <td>19.75</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>5406</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687696</th>\n",
       "      <td>38</td>\n",
       "      <td>165.7</td>\n",
       "      <td>57.06</td>\n",
       "      <td>20.78</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>109.6</td>\n",
       "      <td>1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>6911</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>17.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687697</th>\n",
       "      <td>38</td>\n",
       "      <td>165.7</td>\n",
       "      <td>55.24</td>\n",
       "      <td>20.12</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>145.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8932</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>17.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687698</th>\n",
       "      <td>38</td>\n",
       "      <td>165.7</td>\n",
       "      <td>60.26</td>\n",
       "      <td>21.95</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>84.9</td>\n",
       "      <td>0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8864</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>17.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687699</th>\n",
       "      <td>38</td>\n",
       "      <td>165.7</td>\n",
       "      <td>59.30</td>\n",
       "      <td>21.60</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>107.1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>7455</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>17.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687700</th>\n",
       "      <td>38</td>\n",
       "      <td>165.7</td>\n",
       "      <td>57.56</td>\n",
       "      <td>20.96</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>88.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9737</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>17.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>687701 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height_cm  weight_kg    bmi    activity_type  duration_minutes  \\\n",
       "0        56      165.3      50.55  18.50          Dancing              42.1   \n",
       "1        56      165.3      55.38  20.27         Swimming              66.9   \n",
       "2        56      165.3      56.49  20.68         Swimming              20.0   \n",
       "3        56      165.3      52.23  19.12  Weight Training              23.5   \n",
       "4        56      165.3      53.96  19.75         Swimming              75.0   \n",
       "...     ...        ...        ...    ...              ...               ...   \n",
       "687696   38      165.7      57.06  20.78       Basketball             109.6   \n",
       "687697   38      165.7      55.24  20.12       Basketball             145.3   \n",
       "687698   38      165.7      60.26  21.95             Yoga              84.9   \n",
       "687699   38      165.7      59.30  21.60       Basketball             107.1   \n",
       "687700   38      165.7      57.56  20.96             Yoga              88.3   \n",
       "\n",
       "        intensity  calories_burned  daily_steps  avg_heart_rate  ...  \\\n",
       "0               0              3.3         7128             103  ...   \n",
       "1               0              2.9         7925             102  ...   \n",
       "2               1              2.6         7557             126  ...   \n",
       "3               1             10.7        11120             141  ...   \n",
       "4               1             12.7         5406             112  ...   \n",
       "...           ...              ...          ...             ...  ...   \n",
       "687696          1             13.2         6911             139  ...   \n",
       "687697          0              6.3         8932             113  ...   \n",
       "687698          0              9.1         8864             120  ...   \n",
       "687699          1             32.6         7455             135  ...   \n",
       "687700          2              3.8         9737             164  ...   \n",
       "\n",
       "        fitness_level  gender_F  gender_M  smoking_status_Current  \\\n",
       "0                0.04       1.0       0.0                     0.0   \n",
       "1                0.07       1.0       0.0                     0.0   \n",
       "2                0.09       1.0       0.0                     0.0   \n",
       "3                0.21       1.0       0.0                     0.0   \n",
       "4                0.33       1.0       0.0                     0.0   \n",
       "...               ...       ...       ...                     ...   \n",
       "687696          17.13       1.0       0.0                     0.0   \n",
       "687697          17.16       1.0       0.0                     0.0   \n",
       "687698          17.26       1.0       0.0                     0.0   \n",
       "687699          17.39       1.0       0.0                     0.0   \n",
       "687700          17.43       1.0       0.0                     0.0   \n",
       "\n",
       "        smoking_status_Former  health_condition_Asthma  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "687696                    0.0                      0.0   \n",
       "687697                    0.0                      0.0   \n",
       "687698                    0.0                      0.0   \n",
       "687699                    0.0                      0.0   \n",
       "687700                    0.0                      0.0   \n",
       "\n",
       "        health_condition_Diabetes  health_condition_Hypertension  cluster  \\\n",
       "0                             0.0                            0.0        0   \n",
       "1                             0.0                            0.0        0   \n",
       "2                             0.0                            0.0        0   \n",
       "3                             0.0                            0.0        0   \n",
       "4                             0.0                            0.0        0   \n",
       "...                           ...                            ...      ...   \n",
       "687696                        0.0                            0.0        2   \n",
       "687697                        0.0                            0.0        2   \n",
       "687698                        0.0                            0.0        2   \n",
       "687699                        0.0                            0.0        2   \n",
       "687700                        0.0                            0.0        4   \n",
       "\n",
       "        activity_cluster  \n",
       "0                      4  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      4  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "687696                 0  \n",
       "687697                 0  \n",
       "687698                 1  \n",
       "687699                 0  \n",
       "687700                 1  \n",
       "\n",
       "[687701 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:04.187965Z",
     "iopub.status.busy": "2025-10-06T12:35:04.187688Z",
     "iopub.status.idle": "2025-10-06T12:35:04.260376Z",
     "shell.execute_reply": "2025-10-06T12:35:04.259439Z",
     "shell.execute_reply.started": "2025-10-06T12:35:04.187945Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 687701 entries, 0 to 687700\n",
      "Data columns (total 27 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   age                            687701 non-null  int64  \n",
      " 1   height_cm                      687701 non-null  float64\n",
      " 2   weight_kg                      687701 non-null  float64\n",
      " 3   bmi                            687701 non-null  float64\n",
      " 4   activity_type                  687701 non-null  object \n",
      " 5   duration_minutes               687701 non-null  float64\n",
      " 6   intensity                      687701 non-null  int64  \n",
      " 7   calories_burned                687701 non-null  float64\n",
      " 8   daily_steps                    687701 non-null  int64  \n",
      " 9   avg_heart_rate                 687701 non-null  int64  \n",
      " 10  resting_heart_rate             687701 non-null  float64\n",
      " 11  blood_pressure_systolic        687701 non-null  float64\n",
      " 12  blood_pressure_diastolic       687701 non-null  float64\n",
      " 13  endurance_level                687701 non-null  float64\n",
      " 14  sleep_hours                    687701 non-null  float64\n",
      " 15  stress_level                   687701 non-null  int64  \n",
      " 16  hydration_level                687701 non-null  float64\n",
      " 17  fitness_level                  687701 non-null  float64\n",
      " 18  gender_F                       687701 non-null  float64\n",
      " 19  gender_M                       687701 non-null  float64\n",
      " 20  smoking_status_Current         687701 non-null  float64\n",
      " 21  smoking_status_Former          687701 non-null  float64\n",
      " 22  health_condition_Asthma        687701 non-null  float64\n",
      " 23  health_condition_Diabetes      687701 non-null  float64\n",
      " 24  health_condition_Hypertension  687701 non-null  float64\n",
      " 25  cluster                        687701 non-null  int64  \n",
      " 26  activity_cluster               687701 non-null  int64  \n",
      "dtypes: float64(19), int64(7), object(1)\n",
      "memory usage: 141.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:04.261387Z",
     "iopub.status.busy": "2025-10-06T12:35:04.261168Z",
     "iopub.status.idle": "2025-10-06T12:35:04.450432Z",
     "shell.execute_reply": "2025-10-06T12:35:04.449078Z",
     "shell.execute_reply.started": "2025-10-06T12:35:04.261368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: age\n",
      "age\n",
      "24    18125\n",
      "44    18107\n",
      "61    17806\n",
      "60    17211\n",
      "63    17153\n",
      "56    16955\n",
      "51    16740\n",
      "52    16594\n",
      "21    16446\n",
      "58    16209\n",
      "57    16046\n",
      "34    16023\n",
      "33    15989\n",
      "64    15912\n",
      "40    15819\n",
      "32    15775\n",
      "43    15564\n",
      "20    15425\n",
      "48    15354\n",
      "36    15352\n",
      "50    15346\n",
      "45    15137\n",
      "18    14961\n",
      "31    14677\n",
      "54    14610\n",
      "53    14548\n",
      "47    14518\n",
      "38    14037\n",
      "39    14011\n",
      "42    13997\n",
      "29    13883\n",
      "41    13879\n",
      "55    13660\n",
      "22    13487\n",
      "49    13379\n",
      "23    13301\n",
      "62    12991\n",
      "30    12725\n",
      "46    12417\n",
      "28    12290\n",
      "35    12250\n",
      "59    12190\n",
      "26    12097\n",
      "27    12080\n",
      "37    12042\n",
      "25    10633\n",
      "19     9950\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: height_cm\n",
      "height_cm\n",
      "162.0    4856\n",
      "163.5    4333\n",
      "165.5    4080\n",
      "168.7    3950\n",
      "163.1    3943\n",
      "         ... \n",
      "187.8     215\n",
      "191.7     214\n",
      "189.6     212\n",
      "184.9     206\n",
      "188.4     204\n",
      "Name: count, Length: 431, dtype: int64\n",
      "\n",
      "Column: weight_kg\n",
      "weight_kg\n",
      "55.88    744\n",
      "76.61    706\n",
      "58.29    701\n",
      "54.73    691\n",
      "59.08    688\n",
      "        ... \n",
      "90.99      1\n",
      "97.94      1\n",
      "95.17      1\n",
      "97.78      1\n",
      "95.27      1\n",
      "Name: count, Length: 5261, dtype: int64\n",
      "\n",
      "Column: bmi\n",
      "bmi\n",
      "18.50    41258\n",
      "24.90    39363\n",
      "20.02     1180\n",
      "20.29     1171\n",
      "20.46     1162\n",
      "         ...  \n",
      "24.88      528\n",
      "24.89      512\n",
      "24.84      512\n",
      "24.78      504\n",
      "24.86      503\n",
      "Name: count, Length: 641, dtype: int64\n",
      "\n",
      "Column: activity_type\n",
      "activity_type\n",
      "Yoga               69961\n",
      "Weight Training    69661\n",
      "HIIT               69376\n",
      "Dancing            69193\n",
      "Cycling            69187\n",
      "Basketball         68536\n",
      "Tennis             68533\n",
      "Walking            68077\n",
      "Swimming           68032\n",
      "Running            67145\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: duration_minutes\n",
      "duration_minutes\n",
      "20.0     58043\n",
      "150.7     2961\n",
      "150.8     2414\n",
      "150.6     2200\n",
      "150.9     1676\n",
      "         ...  \n",
      "151.7       17\n",
      "151.8       12\n",
      "152.1        3\n",
      "152.0        2\n",
      "151.9        1\n",
      "Name: count, Length: 1322, dtype: int64\n",
      "\n",
      "Column: intensity\n",
      "intensity\n",
      "1    343433\n",
      "0    206911\n",
      "2    137357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: calories_burned\n",
      "calories_burned\n",
      "6.4     3754\n",
      "6.8     3737\n",
      "6.1     3728\n",
      "8.7     3723\n",
      "7.9     3703\n",
      "        ... \n",
      "78.1       1\n",
      "79.4       1\n",
      "77.4       1\n",
      "82.3       1\n",
      "75.0       1\n",
      "Name: count, Length: 779, dtype: int64\n",
      "\n",
      "Column: daily_steps\n",
      "daily_steps\n",
      "8270     165\n",
      "8440     162\n",
      "8240     160\n",
      "7869     159\n",
      "8994     159\n",
      "        ... \n",
      "15204      1\n",
      "14134      1\n",
      "2246       1\n",
      "14346      1\n",
      "2069       1\n",
      "Name: count, Length: 12984, dtype: int64\n",
      "\n",
      "Column: avg_heart_rate\n",
      "avg_heart_rate\n",
      "126    15541\n",
      "127    15339\n",
      "125    15294\n",
      "129    15173\n",
      "128    15165\n",
      "       ...  \n",
      "206        2\n",
      "201        2\n",
      "84         2\n",
      "204        2\n",
      "82         1\n",
      "Name: count, Length: 125, dtype: int64\n",
      "\n",
      "Column: resting_heart_rate\n",
      "resting_heart_rate\n",
      "71.5    7753\n",
      "70.2    7354\n",
      "70.7    6478\n",
      "68.6    6386\n",
      "69.7    6196\n",
      "        ... \n",
      "57.6     223\n",
      "82.3     223\n",
      "60.0     223\n",
      "82.2     220\n",
      "59.6     213\n",
      "Name: count, Length: 271, dtype: int64\n",
      "\n",
      "Column: blood_pressure_systolic\n",
      "blood_pressure_systolic\n",
      "122.3    5545\n",
      "122.8    4610\n",
      "127.6    4161\n",
      "120.2    4142\n",
      "113.8    4118\n",
      "         ... \n",
      "98.5      217\n",
      "96.0      216\n",
      "139.3     215\n",
      "141.8     212\n",
      "141.0     205\n",
      "Name: count, Length: 476, dtype: int64\n",
      "\n",
      "Column: blood_pressure_diastolic\n",
      "blood_pressure_diastolic\n",
      "78.6     5287\n",
      "82.0     4955\n",
      "76.7     4821\n",
      "80.9     4768\n",
      "84.2     4654\n",
      "         ... \n",
      "105.1     213\n",
      "53.7      213\n",
      "94.2      213\n",
      "59.6      213\n",
      "53.8      211\n",
      "Name: count, Length: 416, dtype: int64\n",
      "\n",
      "Column: endurance_level\n",
      "endurance_level\n",
      "9.87     1208\n",
      "9.64     1206\n",
      "9.69     1200\n",
      "10.00    1197\n",
      "9.82     1197\n",
      "         ... \n",
      "18.39       1\n",
      "18.37       1\n",
      "18.34       1\n",
      "17.24       1\n",
      "17.29       1\n",
      "Name: count, Length: 1379, dtype: int64\n",
      "\n",
      "Column: sleep_hours\n",
      "sleep_hours\n",
      "7.0    28233\n",
      "7.1    27978\n",
      "6.9    27867\n",
      "6.8    27855\n",
      "7.2    27845\n",
      "       ...  \n",
      "4.3      612\n",
      "9.8      559\n",
      "4.2      482\n",
      "9.9      457\n",
      "4.1      304\n",
      "Name: count, Length: 61, dtype: int64\n",
      "\n",
      "Column: stress_level\n",
      "stress_level\n",
      "5     134474\n",
      "6     126395\n",
      "4     114635\n",
      "7     102297\n",
      "3      66292\n",
      "8      64753\n",
      "9      28917\n",
      "2      26927\n",
      "10     11527\n",
      "1      11484\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: hydration_level\n",
      "hydration_level\n",
      "1.6    34651\n",
      "3.3    34540\n",
      "2.2    34535\n",
      "2.6    34530\n",
      "3.4    34505\n",
      "1.9    34490\n",
      "2.4    34488\n",
      "2.5    34478\n",
      "2.7    34468\n",
      "1.7    34465\n",
      "2.9    34461\n",
      "2.0    34453\n",
      "1.8    34326\n",
      "3.1    34284\n",
      "2.3    34242\n",
      "2.8    34224\n",
      "3.2    34213\n",
      "2.1    34007\n",
      "3.0    33964\n",
      "1.5    17195\n",
      "3.5    17182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: fitness_level\n",
      "fitness_level\n",
      "0.12     439\n",
      "5.66     423\n",
      "5.92     423\n",
      "7.49     423\n",
      "7.98     420\n",
      "        ... \n",
      "21.49      1\n",
      "21.67      1\n",
      "21.80      1\n",
      "21.59      1\n",
      "21.54      1\n",
      "Name: count, Length: 2166, dtype: int64\n",
      "\n",
      "Column: gender_F\n",
      "gender_F\n",
      "0.0    348845\n",
      "1.0    338856\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: gender_M\n",
      "gender_M\n",
      "0.0    353678\n",
      "1.0    334023\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: smoking_status_Current\n",
      "smoking_status_Current\n",
      "0.0    581370\n",
      "1.0    106331\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: smoking_status_Former\n",
      "smoking_status_Former\n",
      "0.0    523131\n",
      "1.0    164570\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: health_condition_Asthma\n",
      "health_condition_Asthma\n",
      "0.0    654466\n",
      "1.0     33235\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: health_condition_Diabetes\n",
      "health_condition_Diabetes\n",
      "0.0    622947\n",
      "1.0     64754\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: health_condition_Hypertension\n",
      "health_condition_Hypertension\n",
      "0.0    588264\n",
      "1.0     99437\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: cluster\n",
      "cluster\n",
      "2    158316\n",
      "0    136777\n",
      "1    133473\n",
      "3    131247\n",
      "4    127888\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: activity_cluster\n",
      "activity_cluster\n",
      "0    205101\n",
      "4    138854\n",
      "1    138038\n",
      "3    136332\n",
      "2     69376\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loop through all columns in df and print value counts\n",
    "for col in df.columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:04.451621Z",
     "iopub.status.busy": "2025-10-06T12:35:04.451327Z",
     "iopub.status.idle": "2025-10-06T12:35:04.464805Z",
     "shell.execute_reply": "2025-10-06T12:35:04.463886Z",
     "shell.execute_reply.started": "2025-10-06T12:35:04.451601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_cluster\n",
       "0    205101\n",
       "4    138854\n",
       "1    138038\n",
       "3    136332\n",
       "2     69376\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:04.465820Z",
     "iopub.status.busy": "2025-10-06T12:35:04.465582Z",
     "iopub.status.idle": "2025-10-06T12:35:05.362440Z",
     "shell.execute_reply": "2025-10-06T12:35:05.361778Z",
     "shell.execute_reply.started": "2025-10-06T12:35:04.465800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = df.drop(columns=[\"activity_cluster\", \"cluster\", \"activity_type\", \"avg_heart_rate\"])\n",
    "y = df[\"activity_cluster\"]\n",
    "\n",
    "# selector = SelectKBest(score_func=f_classif, k=20)  # pick top 30 features\n",
    "# X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# selected_features = X.columns[selector.get_support()]\n",
    "# print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:05.363492Z",
     "iopub.status.busy": "2025-10-06T12:35:05.363102Z",
     "iopub.status.idle": "2025-10-06T12:35:05.368122Z",
     "shell.execute_reply": "2025-10-06T12:35:05.367351Z",
     "shell.execute_reply.started": "2025-10-06T12:35:05.363417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import pandas as pd\n",
    "\n",
    "# # Example: classification\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = model.feature_importances_\n",
    "# feat_importances = pd.Series(importances, index=X.columns)\n",
    "# feat_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# print(feat_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:05.369525Z",
     "iopub.status.busy": "2025-10-06T12:35:05.369097Z",
     "iopub.status.idle": "2025-10-06T12:35:05.404650Z",
     "shell.execute_reply": "2025-10-06T12:35:05.403235Z",
     "shell.execute_reply.started": "2025-10-06T12:35:05.369462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_cluster\n",
      "0    205101\n",
      "4    138854\n",
      "1    138038\n",
      "3    136332\n",
      "2     69376\n",
      "Name: count, dtype: int64\n",
      "activity_cluster\n",
      "0    29.824153\n",
      "4    20.191042\n",
      "1    20.072386\n",
      "3    19.824313\n",
      "2    10.088105\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For your case\n",
    "class_counts = df[\"activity_cluster\"].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Or as percentages\n",
    "class_percentages = df[\"activity_cluster\"].value_counts(normalize=True) * 100\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:05.407636Z",
     "iopub.status.busy": "2025-10-06T12:35:05.407368Z",
     "iopub.status.idle": "2025-10-06T12:35:05.481982Z",
     "shell.execute_reply": "2025-10-06T12:35:05.481150Z",
     "shell.execute_reply.started": "2025-10-06T12:35:05.407618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# ---------------------------\n",
    "# Create preprocessing pipeline\n",
    "# ---------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Build full pipeline with SVM\n",
    "# ---------------------------\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(kernel='rbf', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:35:05.483071Z",
     "iopub.status.busy": "2025-10-06T12:35:05.482850Z",
     "iopub.status.idle": "2025-10-06T12:37:21.054235Z",
     "shell.execute_reply": "2025-10-06T12:37:21.053254Z",
     "shell.execute_reply.started": "2025-10-06T12:35:05.483053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: [4 0 2 3 1]\n",
      "Encoded labels: [0 1 2 3 4]\n",
      "Training ensemble model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator XGBClassifier should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Train ensemble with encoded labels\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining ensemble model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mensemble\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Test predictions\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\Wellness Assistant\\Backend\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\Wellness Assistant\\Backend\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:405\u001b[39m, in \u001b[36mVotingClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m.le_.classes_\n\u001b[32m    403\u001b[39m transformed_y = \u001b[38;5;28mself\u001b[39m.le_.transform(y)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\Wellness Assistant\\Backend\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:80\u001b[39m, in \u001b[36m_BaseVoting.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **fit_params):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     names, clfs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.weights) != \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators):\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     84\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m estimators\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\Wellness Assistant\\Backend\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:237\u001b[39m, in \u001b[36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    238\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    239\u001b[39m                 est.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, is_estimator_type.\u001b[34m__name__\u001b[39m[\u001b[32m3\u001b[39m:]\n\u001b[32m    240\u001b[39m             )\n\u001b[32m    241\u001b[39m         )\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[31mValueError\u001b[39m: The estimator XGBClassifier should be a classifier."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Split data 80/20 (train/test)\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Encode target labels to ensure compatibility\n",
    "# -------------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Original labels: {y.unique()}\")\n",
    "print(f\"Encoded labels: {label_encoder.classes_}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Tuned models (updated for new versions)\n",
    "# -------------------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=271,\n",
    "    max_depth=11,\n",
    "    learning_rate=0.2047796426757615,\n",
    "    subsample=0.8851985734223917,\n",
    "    colsample_bytree=0.7033309928502494,\n",
    "    gamma=0.44512356222236044,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=378,\n",
    "    max_depth=11,\n",
    "    learning_rate=0.22408224744749508,\n",
    "    num_leaves=165,\n",
    "    subsample=0.6086742677723623,\n",
    "    colsample_bytree=0.733633308095874,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Ensemble with soft voting\n",
    "# -------------------------------\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('lgbm', lgbm_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Train ensemble with encoded labels\n",
    "# -------------------------------\n",
    "print(\"Training ensemble model...\")\n",
    "ensemble.fit(X_train, y_train_encoded)\n",
    "print(\"Training completed successfully!\")\n",
    "\n",
    "# -------------------------------\n",
    "# Test predictions\n",
    "# -------------------------------\n",
    "y_pred_encoded = ensemble.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation\n",
    "# -------------------------------\n",
    "acc = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "f1 = f1_score(y_test_encoded, y_pred_encoded, average='weighted')\n",
    "\n",
    "print(f\"Ensemble Accuracy: {acc:.4f}\")\n",
    "print(f\"Ensemble F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_encoded))\n",
    "\n",
    "# Convert predictions back to original labels for interpretation\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_original = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "print(f\"\\nSample predictions (original format):\")\n",
    "for i in range(min(10, len(y_pred_original))):\n",
    "    print(f\"Actual: {y_test_original[i]}, Predicted: {y_pred_original[i]}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Save both model and label encoder\n",
    "# -------------------------------\n",
    "print(\"\\nSaving model and label encoder...\")\n",
    "joblib.dump(ensemble, 'fitness_model.joblib')\n",
    "joblib.dump(label_encoder, 'fitness_label_encoder.joblib')\n",
    "print(\"Model and label encoder saved successfully!\")\n",
    "\n",
    "# Test loading\n",
    "print(\"\\nTesting model loading...\")\n",
    "loaded_ensemble = joblib.load('fitness_model.joblib')\n",
    "loaded_label_encoder = joblib.load('fitness_label_encoder.joblib')\n",
    "test_prediction = loaded_ensemble.predict(X_test[:1])\n",
    "print(f\"Test prediction successful: {loaded_label_encoder.inverse_transform(test_prediction)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:21.056057Z",
     "iopub.status.busy": "2025-10-06T12:37:21.055465Z",
     "iopub.status.idle": "2025-10-06T12:37:21.061637Z",
     "shell.execute_reply": "2025-10-06T12:37:21.060761Z",
     "shell.execute_reply.started": "2025-10-06T12:37:21.056040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:21.062415Z",
     "iopub.status.busy": "2025-10-06T12:37:21.062230Z",
     "iopub.status.idle": "2025-10-06T12:37:41.911988Z",
     "shell.execute_reply": "2025-10-06T12:37:41.911253Z",
     "shell.execute_reply.started": "2025-10-06T12:37:21.062400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save\n",
    "joblib.dump(ensemble, 'fitness_model.joblib')\n",
    "\n",
    "# Load\n",
    "ensemble_loaded = joblib.load('fitness_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:41.920310Z",
     "iopub.status.busy": "2025-10-06T12:37:41.920069Z",
     "iopub.status.idle": "2025-10-06T12:37:41.985696Z",
     "shell.execute_reply": "2025-10-06T12:37:41.984779Z",
     "shell.execute_reply.started": "2025-10-06T12:37:41.920288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Keep original continuous values before binning\n",
    "# df[\"fitness_level_original\"] = df[\"fitness_level\"]   # backup\n",
    "# df[\"endurance_level_original\"] = df[\"endurance_level\"]\n",
    "\n",
    "# # Define bins\n",
    "# fitness_bins = [-float(\"inf\"), 7, 14, float(\"inf\")]\n",
    "# fitness_labels = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "# endurance_bins = [-float(\"inf\"), 8.5, 11, float(\"inf\")]\n",
    "# endurance_labels = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "# # Bin data\n",
    "# df[\"fitness_bin\"] = pd.cut(df[\"fitness_level_original\"], bins=fitness_bins, labels=fitness_labels)\n",
    "# df[\"endurance_bin\"] = pd.cut(df[\"endurance_level_original\"], bins=endurance_bins, labels=endurance_labels)\n",
    "\n",
    "# # Compute mean values per bin\n",
    "# fitness_means = df.groupby(\"fitness_bin\")[\"fitness_level_original\"].mean().to_dict()\n",
    "# endurance_means = df.groupby(\"endurance_bin\")[\"endurance_level_original\"].mean().to_dict()\n",
    "\n",
    "# print(\"Representative values for Fitness bins:\", fitness_means)\n",
    "# print(\"Representative values for Endurance bins:\", endurance_means)\n",
    "\n",
    "# # ------------------------------\n",
    "# # Function for prediction mapping\n",
    "# # ------------------------------\n",
    "# def map_user_input_to_value(fitness_bin, endurance_bin):\n",
    "#     \"\"\"Convert user-friendly Low/Medium/High input to numeric values based on dataset means\"\"\"\n",
    "#     fitness_val = fitness_means.get(fitness_bin, None)\n",
    "#     endurance_val = endurance_means.get(endurance_bin, None)\n",
    "#     return fitness_val, endurance_val\n",
    "\n",
    "# # ------------------------------\n",
    "# # Example usage\n",
    "# # ------------------------------\n",
    "# user_fitness = \"Medium\"   # user selects\n",
    "# user_endurance = \"Low\"\n",
    "\n",
    "# fitness_val, endurance_val = map_user_input_to_value(user_fitness, user_endurance)\n",
    "\n",
    "# print(f\"Mapped values → Fitness: {fitness_val}, Endurance: {endurance_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:41.986755Z",
     "iopub.status.busy": "2025-10-06T12:37:41.986513Z",
     "iopub.status.idle": "2025-10-06T12:37:41.993612Z",
     "shell.execute_reply": "2025-10-06T12:37:41.992531Z",
     "shell.execute_reply.started": "2025-10-06T12:37:41.986712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# import numpy as np\n",
    "\n",
    "# # ---------------------------\n",
    "# # Custom transformer: Deep feature extractor\n",
    "# # ---------------------------\n",
    "# class DeepFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, input_dim, embedding_dim=32, epochs=10, batch_size=32):\n",
    "#         self.input_dim = input_dim\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.model = None\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         # Simple autoencoder-like NN to learn embeddings\n",
    "#         inputs = tf.keras.Input(shape=(self.input_dim,))\n",
    "#         x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "#         x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "#         embeddings = tf.keras.layers.Dense(self.embedding_dim, activation=\"relu\")(x)\n",
    "#         outputs = tf.keras.layers.Dense(self.input_dim, activation=\"linear\")(embeddings)\n",
    "\n",
    "#         autoencoder = tf.keras.Model(inputs, outputs)\n",
    "#         autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "#         autoencoder.fit(X, X, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "#         # Store encoder part only\n",
    "#         self.model = tf.keras.Model(inputs, embeddings)\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return self.model.predict(X, verbose=0)\n",
    "\n",
    "# # ---------------------------\n",
    "# # Preprocessing pipeline\n",
    "# # ---------------------------\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numeric_cols),\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # ---------------------------\n",
    "# # Hybrid pipeline: Preprocess → Deep NN features → SVM\n",
    "# # ---------------------------\n",
    "# hybrid_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('deep_features', DeepFeatureExtractor(input_dim=len(numeric_cols) + len(categorical_cols))),\n",
    "#     ('classifier', SVC(kernel='rbf', random_state=42))\n",
    "# ])\n",
    "\n",
    "# # ---------------------------\n",
    "# # Train/test split\n",
    "# # ---------------------------\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Fit hybrid model\n",
    "# hybrid_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred = hybrid_pipeline.predict(X_test)\n",
    "# print(\"Hybrid Model Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:41.995376Z",
     "iopub.status.busy": "2025-10-06T12:37:41.994789Z",
     "iopub.status.idle": "2025-10-06T12:37:42.024217Z",
     "shell.execute_reply": "2025-10-06T12:37:42.023472Z",
     "shell.execute_reply.started": "2025-10-06T12:37:41.995347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# import pandas as pd\n",
    "\n",
    "# # Example: X, y already prepared\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# # --------------------------------------------\n",
    "# # Objective functions for each model\n",
    "# # --------------------------------------------\n",
    "# def objective_rf(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "#     max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "#     model = RandomForestClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         min_samples_split=min_samples_split,\n",
    "#         min_samples_leaf=min_samples_leaf,\n",
    "#         max_features=max_features,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# def objective_dt(trial):\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "#     criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "\n",
    "#     model = DecisionTreeClassifier(\n",
    "#         max_depth=max_depth,\n",
    "#         min_samples_split=min_samples_split,\n",
    "#         min_samples_leaf=min_samples_leaf,\n",
    "#         criterion=criterion,\n",
    "#         random_state=42\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# def objective_gb(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "\n",
    "#     model = GradientBoostingClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "#         max_depth=max_depth,\n",
    "#         random_state=42\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# def objective_xgb(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "\n",
    "#     model = XGBClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "#         max_depth=max_depth,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         random_state=42,\n",
    "#         eval_metric='logloss',\n",
    "#         use_label_encoder=False\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# def objective_lgbm(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "#     num_leaves = trial.suggest_int('num_leaves', 15, 150)\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "\n",
    "#     model = LGBMClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "#         num_leaves=num_leaves,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         random_state=42,\n",
    "#         verbose=-1\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# def objective_cat(trial):\n",
    "#     depth = trial.suggest_int('depth', 2, 10)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "#     iterations = trial.suggest_int('iterations', 100, 1000)\n",
    "\n",
    "#     model = CatBoostClassifier(\n",
    "#         depth=depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         iterations=iterations,\n",
    "#         random_state=42,\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_val)\n",
    "#     return accuracy_score(y_val, preds)\n",
    "\n",
    "# # --------------------------------------------\n",
    "# # Run Optuna for each model\n",
    "# # --------------------------------------------\n",
    "# study_rf = optuna.create_study(direction='maximize')\n",
    "# study_rf.optimize(objective_rf, n_trials=30)\n",
    "# print(\"Best RF params:\", study_rf.best_params)\n",
    "\n",
    "# study_dt = optuna.create_study(direction='maximize')\n",
    "# study_dt.optimize(objective_dt, n_trials=30)\n",
    "# print(\"Best DecisionTree params:\", study_dt.best_params)\n",
    "\n",
    "# study_gb = optuna.create_study(direction='maximize')\n",
    "# study_gb.optimize(objective_gb, n_trials=30)\n",
    "# print(\"Best GradientBoosting params:\", study_gb.best_params)\n",
    "\n",
    "# study_xgb = optuna.create_study(direction='maximize')\n",
    "# study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "# print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "\n",
    "# study_lgbm = optuna.create_study(direction='maximize')\n",
    "# study_lgbm.optimize(objective_lgbm, n_trials=30)\n",
    "# print(\"Best LGBM params:\", study_lgbm.best_params)\n",
    "\n",
    "# study_cat = optuna.create_study(direction='maximize')\n",
    "# study_cat.optimize(objective_cat, n_trials=30)\n",
    "# print(\"Best CatBoost params:\", study_cat.best_params)\n",
    "\n",
    "# # --------------------------------------------\n",
    "# # Evaluate best model on the test set\n",
    "# # --------------------------------------------\n",
    "# best_rf = RandomForestClassifier(**study_rf.best_params, random_state=42)\n",
    "# best_rf.fit(X_train, y_train)\n",
    "# y_pred_rf = best_rf.predict(X_test)\n",
    "# print(\"RF Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "# print(\"RF Test F1:\", f1_score(y_test, y_pred_rf, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:42.025215Z",
     "iopub.status.busy": "2025-10-06T12:37:42.025007Z",
     "iopub.status.idle": "2025-10-06T12:37:42.057932Z",
     "shell.execute_reply": "2025-10-06T12:37:42.056422Z",
     "shell.execute_reply.started": "2025-10-06T12:37:42.025198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "\n",
    "# # -----------------------------\n",
    "# # 1. Prepare Data\n",
    "# # -----------------------------\n",
    "# X = df.drop(columns=[\"activity_cluster\", \"cluster\", \"activity_type\"])\n",
    "# y = df[\"activity_cluster\"]\n",
    "\n",
    "# # Scale features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # Convert to torch tensors\n",
    "# X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "# X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "# y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "# y_val = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "# # Create DataLoaders\n",
    "# batch_size = 2048\n",
    "# train_dataset = TensorDataset(X_train, y_train)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# val_dataset = TensorDataset(X_val, y_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 2. Improved Deep Network\n",
    "# # -----------------------------\n",
    "# class ImprovedNet(nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.4),\n",
    "            \n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "            \n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.2),\n",
    "            \n",
    "#             nn.Linear(128, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# num_classes = len(np.unique(y))\n",
    "# model = ImprovedNet(input_dim, num_classes)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 3. Training Setup\n",
    "# # -----------------------------\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# # Scheduler: reduce LR by factor of 0.5 if val loss hasn’t improved for 3 epochs\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "# )\n",
    "\n",
    "# epochs = 50\n",
    "# patience = 7  # early stopping patience\n",
    "# best_val_loss = float('inf')\n",
    "# counter = 0\n",
    "\n",
    "# # -----------------------------\n",
    "# # 4. Training Loop with Early Stopping + Scheduler\n",
    "# # -----------------------------\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for batch_x, batch_y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_x)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_losses = []\n",
    "#     val_preds = []\n",
    "#     val_targets = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch_x, batch_y in val_loader:\n",
    "#             outputs = model(batch_x)\n",
    "#             val_loss = criterion(outputs, batch_y)\n",
    "#             val_losses.append(val_loss.item())\n",
    "#             preds = outputs.argmax(dim=1)\n",
    "#             val_preds.append(preds)\n",
    "#             val_targets.append(batch_y)\n",
    "\n",
    "#     avg_val_loss = np.mean(val_losses)\n",
    "#     val_preds = torch.cat(val_preds)\n",
    "#     val_targets = torch.cat(val_targets)\n",
    "#     val_acc = accuracy_score(val_targets.cpu(), val_preds.cpu())\n",
    "\n",
    "#     # Step scheduler\n",
    "#     scheduler.step(avg_val_loss)\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{epochs}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_acc:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "#     # Early Stopping\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         counter = 0\n",
    "#         torch.save(model.state_dict(), \"best_model.pth\")  # save best model\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(\"Early stopping triggered!\")\n",
    "#             break\n",
    "\n",
    "# print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T12:37:42.059566Z",
     "iopub.status.busy": "2025-10-06T12:37:42.059228Z",
     "iopub.status.idle": "2025-10-06T12:37:42.089652Z",
     "shell.execute_reply": "2025-10-06T12:37:42.088793Z",
     "shell.execute_reply.started": "2025-10-06T12:37:42.059544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # ---------------------------\n",
    "# # Your existing data split\n",
    "# X = df.drop(columns=[\"activity_cluster\", \"cluster\", \"activity_type\"])\n",
    "# y = df[\"activity_cluster\"]\n",
    "\n",
    "# # Scale numeric features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # Encode labels\n",
    "# le = LabelEncoder()\n",
    "# y_train_enc = le.fit_transform(y_train)\n",
    "# y_val_enc = le.transform(y_val)\n",
    "\n",
    "# num_classes = len(le.classes_)\n",
    "# input_dim = X_train.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8237142,
     "sourceId": 13010713,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
